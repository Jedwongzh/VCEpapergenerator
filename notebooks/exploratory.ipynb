{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis for VCE Papers\n",
    "\n",
    "This notebook is intended for exploratory data analysis (EDA) of the VCE Methods and Specialist Maths papers. It will include visualizations, data summaries, and insights that can help in understanding the dataset and guiding the model training process.\n",
    "\n",
    "Here’s a suggested workflow:\n",
    "\n",
    "1. **Structure the Text Data:**  \n",
    "   Write a script to read each txt file and, if possible, split the content into meaningful components (like questions, instructions, and answer sections). You might annotate or tag these sections using regular expressions.\n",
    "\n",
    "2. **Convert to a Structured Format:**  \n",
    "   Convert the cleaned text into a structured format (e.g., CSV or JSONL) where each record contains fields such as exam type, question type, or section. This makes it easier for downstream analysis and model training.\n",
    "\n",
    "3. **Exploratory Data Analysis (EDA):**  \n",
    "   Use your notebook to load the structured data and inspect distributions. Verify that questions and metadata are captured correctly. Adjust your parsing if needed.\n",
    "\n",
    "4. **Dataset Splitting:**  \n",
    "   Split your structured data into training, validation, and test sets. Make sure each exam’s characteristics are preserved in each split.\n",
    "\n",
    "5. **Model Preparation:**  \n",
    "   Decide whether you want to fine-tune one language model or separate models for each exam type (or both). Prepare your training pipeline accordingly—tokenize the structured data and set up your training configuration.\n",
    "\n",
    "6. **Training and Evaluation:**  \n",
    "   Train the model(s) on the structured and cleaned data. Evaluate the model outputs by comparing the generated test papers with your expectations, then iterate on cleaning and structuring as needed.\n",
    "\n",
    "This workflow will help you transition from raw txt files to a robust model training pipeline for generating VCE test papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy\n",
    "# Set visualization style\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Define paths to processed data\n",
    "methods_data_path1 = '../data/processed/proc_methods/s1/'\n",
    "methods_data_path2 = '../data/processed/proc_methods/s2/'\n",
    "specialist_data_path1 = '../data/processed/proc_specialist/s1'\n",
    "specialist_data_path2 = '../data/processed/proc_specialist/s2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specialist Exam 1 Files:\n",
      "['2000-heffernan-exam-1.txt', '2000-mav-exam-1.txt', '2000-vcaa-exam-1.txt', '2001-heffernan-exam-1.txt', '2001-mav-exam-1.txt']\n",
      "\n",
      "Specialist Exam 2 Files:\n",
      "['2000-heffernan-exam-2.txt', '2000-mav-exam-2.txt', '2000-vcaa-exam-2.txt', '2001-heffernan-exam-2.txt', '2001-mav-exam-2.txt']\n",
      "Specialist Data Exam 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-heffernan-exam-1.txt</td>\n",
       "      <td>Student Name............ ........................</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-mav-exam-1.txt</td>\n",
       "      <td>The Mathematica 1 Association of Victoria 2000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-vcaa-exam-1.txt</td>\n",
       "      <td>1 SPECMATH EXAM 1 A Victorian Certificate of E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-heffernan-exam-1.txt</td>\n",
       "      <td>Student Name…………………………………… SPECIALIST MATHEMAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-mav-exam-1.txt</td>\n",
       "      <td>The Mathematica 1 Association of Victoria 2001...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    filename  \\\n",
       "0  2000-heffernan-exam-1.txt   \n",
       "1        2000-mav-exam-1.txt   \n",
       "2       2000-vcaa-exam-1.txt   \n",
       "3  2001-heffernan-exam-1.txt   \n",
       "4        2001-mav-exam-1.txt   \n",
       "\n",
       "                                             content  \n",
       "0  Student Name............ ........................  \n",
       "1  The Mathematica 1 Association of Victoria 2000...  \n",
       "2  1 SPECMATH EXAM 1 A Victorian Certificate of E...  \n",
       "3  Student Name…………………………………… SPECIALIST MATHEMAT...  \n",
       "4  The Mathematica 1 Association of Victoria 2001...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Specialist Data Exam 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-heffernan-exam-2.txt</td>\n",
       "      <td>Student Nam e....................................</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-mav-exam-2.txt</td>\n",
       "      <td>The Mathematica 1 Association of Victoria 2000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-vcaa-exam-2.txt</td>\n",
       "      <td>Victorian Certificate of Education 2000 Figure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-heffernan-exam-2.txt</td>\n",
       "      <td>Student Name…………………………………… SPECIALIST MATHEMAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-mav-exam-2.txt</td>\n",
       "      <td>The Mathematica 1 Association of Victoria 2001...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    filename  \\\n",
       "0  2000-heffernan-exam-2.txt   \n",
       "1        2000-mav-exam-2.txt   \n",
       "2       2000-vcaa-exam-2.txt   \n",
       "3  2001-heffernan-exam-2.txt   \n",
       "4        2001-mav-exam-2.txt   \n",
       "\n",
       "                                             content  \n",
       "0  Student Nam e....................................  \n",
       "1  The Mathematica 1 Association of Victoria 2000...  \n",
       "2  Victorian Certificate of Education 2000 Figure...  \n",
       "3  Student Name…………………………………… SPECIALIST MATHEMAT...  \n",
       "4  The Mathematica 1 Association of Victoria 2001...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Folder path for Specialist Exam 1 (s1)\n",
    "s1_folder = specialist_data_path1  \n",
    "# Folder path for Specialist Exam 2 (s2)\n",
    "s2_folder = specialist_data_path2\n",
    "\n",
    "\n",
    "# List all files in the folder that end with .txt (case-insensitive)\n",
    "#SPESH\n",
    "txt_files_s1 = [f for f in os.listdir(s1_folder) if f.lower().endswith('.txt')]\n",
    "txt_files_s2 = [f for f in os.listdir(s2_folder) if f.lower().endswith('.txt')]\n",
    "\n",
    "# Display the first few filenames to verify\n",
    "#SPESH\n",
    "print(\"Specialist Exam 1 Files:\")\n",
    "print(txt_files_s1[:5])\n",
    "print(\"\\nSpecialist Exam 2 Files:\")\n",
    "print(txt_files_s2[:5])\n",
    "\n",
    "\n",
    "data_s1 = []\n",
    "data_s2 = []\n",
    "\n",
    "\n",
    "# Load the data from each file into a DataFrame\n",
    "#SPESH\n",
    "for filename in txt_files_s1:\n",
    "    file_path = os.path.join(s1_folder, filename)\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    data_s1.append({'filename': filename, 'content': content})\n",
    "\n",
    "for filename in txt_files_s2:\n",
    "    file_path = os.path.join(s2_folder, filename)\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    data_s2.append({'filename': filename, 'content': content})\n",
    "    \n",
    "    \n",
    "# Create a DataFrame from the loaded data\n",
    "specialist_data1 = pd.DataFrame(data_s1)\n",
    "specialist_data2 = pd.DataFrame(data_s2)\n",
    "\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(\"Specialist Data Exam 1:\")\n",
    "display(specialist_data1.head())\n",
    "print(\"\\nSpecialist Data Exam 2:\")\n",
    "display(specialist_data2.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Specialist Exam 1 CSV to: ../data/processed/proc_specialist/s1\\processed_data_s1.csv\n",
      "Saved Specialist Exam 2 CSV to: ../data/processed/proc_specialist/s2\\processed_data_s2.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define CSV output paths. Adjust these paths if you prefer a different location.\n",
    "specialist_csv_path1 = os.path.join(s1_folder, 'processed_data_s1.csv')\n",
    "specialist_csv_path2 = os.path.join(s2_folder, 'processed_data_s2.csv')\n",
    "\n",
    "# Save the DataFrames to CSV files\n",
    "specialist_data1.to_csv(specialist_csv_path1, index=False, encoding='utf-8', escapechar='\\\\')\n",
    "specialist_data2.to_csv(specialist_csv_path2, index=False, encoding='utf-8', escapechar='\\\\')\n",
    "\n",
    "print(f\"Saved Specialist Exam 1 CSV to: {specialist_csv_path1}\")\n",
    "print(f\"Saved Specialist Exam 2 CSV to: {specialist_csv_path2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#METHODS\n",
    "# Folder path for Methods Exam 1 (m1)\n",
    "m1_folder = methods_data_path1\n",
    "# Folder path for Methods Exam 2 (m2)\n",
    "m2_folder = methods_data_path2\n",
    "\n",
    "# List all files in the folder that end with .txt (case-insensitive)\n",
    "txt_files_m1 = [f for f in os.listdir(m1_folder) if f.lower().endswith('.txt')]\n",
    "txt_files_m2 = [f for f in os.listdir(m2_folder) if f.lower().endswith('.txt')]\n",
    "\n",
    "# Display the first few filenames to verify\n",
    "print(\"\\nMethods Exam 1 Files:\")\n",
    "print(txt_files_m1[:5])\n",
    "print(\"\\nMethods Exam 2 Files:\")\n",
    "print(txt_files_m2[:5])\n",
    "\n",
    "# Load the data from each file into a DataFrame\n",
    "data_m1 = []\n",
    "data_m2 = []\n",
    "\n",
    "for filename in txt_files_m1:\n",
    "    file_path = os.path.join(m1_folder, filename)\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    data_m1.append({'filename': filename, 'content': content})\n",
    "    \n",
    "for filename in txt_files_m2:\n",
    "    file_path = os.path.join(m2_folder, filename)\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    data_m2.append({'filename': filename, 'content': content})\n",
    "    \n",
    "# Create a DataFrame from the loaded data\n",
    "methods_data1 = pd.DataFrame(data_m1)\n",
    "methods_data2 = pd.DataFrame(data_m2)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(\"\\nMethods Data Exam 1:\")\n",
    "display(methods_data1.head())\n",
    "print(\"\\nMethods Data Exam 2:\")\n",
    "display(methods_data2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Specialist Exam 1 questions CSV to: ../data/processed/proc_specialist/s1\\processed_data_s1_questions.csv\n",
      "Saved Specialist Exam 2 questions CSV to: ../data/processed/proc_specialist/s2\\processed_data_s2_questions.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def split_questions(text):\n",
    "    \"\"\"\n",
    "    Splits the given text into a list of questions based on occurrences of the pattern:\n",
    "    \"Question\" followed by one or more spaces and a digit (e.g., \"Question 1\").\n",
    "    Only segments that start with this pattern are returned.\n",
    "    \"\"\"\n",
    "    # Split based on positive lookahead for the pattern\n",
    "    parts = re.split(r'(?i)(?=Question\\s+\\d)', text)\n",
    "    # Filter parts and only keep those that begin with \"Question\" followed by a digit\n",
    "    questions = [p.strip() for p in parts if re.match(r'(?i)^Question\\s+\\d', p.strip())]\n",
    "    return questions\n",
    "\n",
    "# Example usage: for Specialist Exam 1 Data\n",
    "s1_data = pd.read_csv(os.path.join(specialist_data_path1, 'processed_data_s1.csv'))\n",
    "s2_data = pd.read_csv(os.path.join(specialist_data_path2, 'processed_data_s2.csv'))\n",
    "\n",
    "# Handle missing values in 'content' column\n",
    "s1_data['content'] = s1_data['content'].fillna('')\n",
    "s2_data['content'] = s2_data['content'].fillna('')\n",
    "\n",
    "# Apply the splitting function to create a new 'questions' column.\n",
    "s1_data['questions'] = s1_data['content'].apply(split_questions)\n",
    "s2_data['questions'] = s2_data['content'].apply(split_questions)\n",
    "\n",
    "# Explode the list of questions into separate rows for Specialist Exam 1\n",
    "s1_exploded = s1_data.explode('questions').reset_index(drop=True)\n",
    "s1_exploded['question_num'] = s1_exploded.groupby('filename').cumcount() + 1\n",
    "\n",
    "# Explode the list of questions into separate rows for Specialist Exam 2\n",
    "s2_exploded = s2_data.explode('questions').reset_index(drop=True)\n",
    "s2_exploded['question_num'] = s2_exploded.groupby('filename').cumcount() + 1\n",
    "\n",
    "# Optionally, keep only relevant columns: filename, question_num, questions\n",
    "s1_final = s1_exploded[['filename', 'question_num', 'questions']]\n",
    "s2_final = s2_exploded[['filename', 'question_num', 'questions']]\n",
    "\n",
    "# Define CSV output paths (adjust as needed)\n",
    "s1_csv_path = os.path.join(specialist_data_path1, 'processed_data_s1_questions.csv')\n",
    "s2_csv_path = os.path.join(specialist_data_path2, 'processed_data_s2_questions.csv')\n",
    "\n",
    "# Save the final DataFrames as CSV files\n",
    "s1_final.to_csv(s1_csv_path, index=False, encoding='utf-8', escapechar='\\\\')\n",
    "s2_final.to_csv(s2_csv_path, index=False, encoding='utf-8', escapechar='\\\\')\n",
    "\n",
    "print(f\"Saved Specialist Exam 1 questions CSV to: {s1_csv_path}\")\n",
    "print(f\"Saved Specialist Exam 2 questions CSV to: {s2_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage: for Methods Exam Data\n",
    "m1_data = pd.read_csv(os.path.join(methods_data_path1, 'processed_data_m1.csv'))\n",
    "m2_data = pd.read_csv(os.path.join(methods_data_path2, 'processed_data_m2.csv'))\n",
    "\n",
    "# Handle missing values in the 'content' column.\n",
    "m1_data['content'] = m1_data['content'].fillna('')\n",
    "m2_data['content'] = m2_data['content'].fillna('')\n",
    "\n",
    "# Apply the splitting function to create a new 'questions' column.\n",
    "m1_data['questions'] = m1_data['content'].apply(split_questions)\n",
    "m2_data['questions'] = m2_data['content'].apply(split_questions)\n",
    "\n",
    "# Explode the list of questions into separate rows for Methods Exam 1.\n",
    "m1_exploded = m1_data.explode('questions').reset_index(drop=True)\n",
    "m1_exploded['question_num'] = m1_exploded.groupby('filename').cumcount() + 1\n",
    "\n",
    "# Explode the list of questions into separate rows for Methods Exam 2.\n",
    "m2_exploded = m2_data.explode('questions').reset_index(drop=True)\n",
    "m2_exploded['question_num'] = m2_exploded.groupby('filename').cumcount() + 1\n",
    "\n",
    "# Optionally, keep only relevant columns: filename, question_num, and questions.\n",
    "m1_final = m1_exploded[['filename', 'question_num', 'questions']]\n",
    "m2_final = m2_exploded[['filename', 'question_num', 'questions']]\n",
    "\n",
    "# Define CSV output paths (adjust as needed).\n",
    "m1_csv_path = os.path.join(methods_data_path1, 'processed_data_m1_questions.csv')\n",
    "m2_csv_path = os.path.join(methods_data_path2, 'processed_data_m2_questions.csv')\n",
    "\n",
    "# Save the final DataFrames as CSV files.\n",
    "m1_final.to_csv(m1_csv_path, index=False, encoding='utf-8', escapechar='\\\\')\n",
    "m2_final.to_csv(m2_csv_path, index=False, encoding='utf-8', escapechar='\\\\')\n",
    "\n",
    "print(f\"Saved Methods Exam 1 questions CSV to: {m1_csv_path}\")\n",
    "print(f\"Saved Methods Exam 2 questions CSV to: {m2_csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECE4179",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
